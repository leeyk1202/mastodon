# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file

User-agent: *
Disallow: /media_proxy/
Disallow: /interact/

###############################################################################################################################
# AI Bots - Crawlers/scrapers and data harvesters. Blocking these should not negatively effect the end user.
###############################################################################################################################

# OpenAI Scraper/Crawler/Assistant https://platform.openai.com/docs/bots
# "GPTBot is used to make our generative AI foundation models more useful and safe. It is used to crawl content that may be used in training our generative AI foundation models."
User-agent: GPTBot
# "When users ask ChatGPT or a CustomGPT a question, it may visit a web page to help answer"
User-agent: ChatGPT-User
# "OAI-SearchBot is used to link to and surface websites in search results in the SearchGPT prototype"
User-agent: OAI-SearchBot

# Amazon Alexa Crawler https://developer.amazon.com/amazonbot
# "Amazonbot is Amazon's web crawler used to improve our services, such as enabling Alexa to answer even more questions for customers"
User-agent: Amazonbot

# Apple Siri Crawler https://support.apple.com/en-au/HT204683
# "Applebot is the web crawler for Apple. Products like Siri and Spotlight Suggestions use Applebot."
User-agent: Applebot

# Apple AI models https://support.apple.com/en-au/119829
# "Allowing Applebot-Extended will help improve the capabilities and quality of Appleâ€™s generative AI models over time."
User-agent: Applebot-Extended

# Common Crawl https://commoncrawl.org/ccbot
User-agent: CCBot

# Facebook AI models https://developers.facebook.com/docs/sharing/bot/
# "FacebookBot crawls public web pages to improve language models for our speech recognition technology. "
User-agent: FacebookBot

# Facebook AI models https://developers.facebook.com/docs/sharing/webmasters/crawler
# "training AI models or improving products by indexing content directly"
User-agent: Meta-ExternalAgent

# Googles Gemini Apps and Vertex AI https://developers.google.com/search/docs/crawling-indexing/overview-google-crawlers
# "help improve Gemini Apps and Vertex AI generative APIs, including future generations of models that power those products."
User-agent: Google-Extended

###############################################################################################################################

# https://docs.perplexity.ai/docs/perplexity-bot
User-agent: PerplexityBot

# Anthropic AI Modals https://support.anthropic.com/en/articles/8896518-does-anthropic-crawl-data-from-the-web-and-how-can-site-owners-block-the-crawler
# "Our mission to build safe and reliable frontier systems and advance the field of responsible AI development"
User-agent: anthropic-ai
User-agent: ClaudeBot
User-agent: Claude-Web

Disallow: /
